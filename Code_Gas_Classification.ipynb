{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2602cdba-6725-4d97-9197-c6d686d930ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This project is on Gas Classification for 11 gases, using 100 GB of data obtained from sensor modules.\n",
    "# Each sensor module included 8 sensors and was placed in 6 horizontal and 9 vertical locations for measurements under 11 different target gases.\n",
    "# The goal is to predict the target gas out of 11 possibilities, using the raw data file received from the sensor module.\n",
    "\n",
    "# Import necessary libraries\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Download the data from https://archive.ics.uci.edu/dataset/251/gas+sensor+arrays+in+open+sampling+settings\n",
    "\n",
    "# Create a list of file paths\n",
    "root_path = 'path/to/your/data/directory'\n",
    "paths = [os.path.join(root, subfolder) for root, _, subfolders in os.walk(root_path) for subfolder in subfolders]\n",
    "\n",
    "\n",
    "# Create a list of target gases\n",
    "gas_list = [folder for folder in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, folder))]\n",
    "\n",
    "\n",
    "# Create a folder for results\n",
    "results_dir = os.path.abspath(os.path.join(root_path, os.pardir, 'results'))\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Define the processed_data array\n",
    "processed_data = np.zeros((0, 12), dtype='int8')\n",
    "\n",
    "\n",
    "# Make a loop for all raw data files\n",
    "for file in paths:\n",
    "    raw_data = pd.read_csv(file, delimiter='\\t', header=None, usecols=[filecol for filecol in range(1, 92)],\n",
    "                           engine='python', dtype='int16')\n",
    "\n",
    "\n",
    "    # Define a new_data array for the new raw data file\n",
    "    new_data = np.zeros((1, 12), dtype='int8')\n",
    "\n",
    "    \n",
    "    # Find the common parameters for each data file\n",
    "    fan = np.mean(raw_data[1])\n",
    "    temperature = np.mean(raw_data[9])\n",
    "    RH = np.mean(raw_data[10])\n",
    "    gas_number = 1 + gas_list.index(file.split(os.path.sep)[-3])\n",
    "\n",
    "    new_data[0, 0] = temperature\n",
    "    new_data[0, 1] = RH\n",
    "    new_data[0, 2] = fan\n",
    "    new_data[0, 11] = gas_number\n",
    "\n",
    "    \n",
    "    # Calculate the responses of 8 sensors\n",
    "    for vertical_location in range(9):\n",
    "        col = 12 + 9 * vertical_location\n",
    "        for sensor_number in range(8):\n",
    "            r1 = np.max(raw_data[col + sensor_number])\n",
    "            r2 = np.min(raw_data[col + sensor_number])\n",
    "            new_data[0, sensor_number + 3] = 100 * (r2 - r1) / r1\n",
    "        processed_data = np.concatenate([processed_data, new_data])\n",
    "\n",
    "\n",
    "# Convert the processed_data array to a dataframe\n",
    "processed_data_df = pd.DataFrame(processed_data).astype('int8')\n",
    "\n",
    "\n",
    "# Save the processed data dataframe as a CSV, overwriting the previous CSV file\n",
    "savepath = os.path.join(results_dir, 'processed_data.csv')\n",
    "processed_data_df.to_csv(savepath, mode='w', index=False, header=None)\n",
    "\n",
    "\n",
    "# Define features and labels, and split the data\n",
    "x = processed_data_df.iloc[:, 0:-1]  # Features\n",
    "y = processed_data_df.iloc[:, -1]    # Labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=0.3, shuffle=True)\n",
    "\n",
    "\n",
    "# Display the sizes of the train and test datasets\n",
    "print(\"Training feature matrix shape:\", x_train.shape)\n",
    "print(\"Testing feature matrix shape:\", x_test.shape)\n",
    "print(\"Training target matrix shape:\", y_train.shape)\n",
    "print(\"Testing target matrix shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Model building\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=200, criterion='entropy', random_state=1)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "# Model evaluation\n",
    "true_labels = y_test\n",
    "predicted_labels = y_pred\n",
    "\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "print(report)\n",
    "\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ROC and AUC\n",
    "\n",
    "# Create a multiclass classifier \n",
    "clf_ovr = OneVsRestClassifier(RandomForestClassifier(n_estimators=50, max_depth=200, \n",
    "                                                        criterion='entropy', random_state=1))\n",
    "\n",
    "# Fit the classifier\n",
    "clf_ovr.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Calculate the predicted probabilities\n",
    "predicted_probs = clf_ovr.predict_proba(x_test)\n",
    "\n",
    "\n",
    "# Convert numerical labels to a binary indicator matrix\n",
    "true_labels_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store the ROC AUC scores for each class\n",
    "roc_auc = {}\n",
    "\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "n_classes = true_labels_bin.shape[1]\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(true_labels_bin[:, i], predicted_probs[:, i])\n",
    "    roc_auc[i] = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Class {i+1} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Add the diagonal line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Set plot properties\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass Receiver Operating Characteristic (OvR)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot Precision-Recall Curve for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    precision, recall, _ = precision_recall_curve(true_labels_bin[:, i], predicted_probs[:, i])\n",
    "    plt.plot(recall, precision, label=f'Class {i+1}')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
